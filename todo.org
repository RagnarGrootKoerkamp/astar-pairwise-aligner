#+TITLE: Todo

List of TODOs and other quick remarks.

* Statistics
** TODO avg total estimated distance
** TODO max number of consecutive matches
** TODO contribution to h from matches and distance heuristic
** TODO heuristic time
** TODO number of skipped matches
** TODO pruning time
** TODO Use ~explored/path-len~ for band, instead of ~explored/max(n,m)~

* Code
** TODO fuzzing/testing that fast impls equal slow impls
** TODO efficient pruning: skip explored states that have outdated heuristic value (aka pruning with offset)
** TODO Investigate doing long jumps on matching diagonals.
** TODO Rename max_match_cost to something that includes the +1 that's present everywhere.
** TODO Make a separate type for transformed positions
** TODO Parameter for enabling greedy matching
** TODO Remove sorting from BucketHeap? (Doesn't matter for A*, but may help for cache locality.)
** TODO Colour ~print_heuristic~ by contours instead of by parent.

* MSA (delayed; pruning complications)
** TODO instantiate one heuristic per pair of sequences
** TODO run A* on the one-by-one step graph

*  Edit Distance
** TODO Run SeedHeuristic with l=1 as edit distance computation algorithm.
   - This generalizes the LCS Contours algorithm to edit distance.
   - For l>1, it generalizes the LCS_{k[+]}  algorithm and provides a lower bound.

*  Seeds
** TODO Dynamic seeding, either greedy or using some DP[i, j, distance].
   - Maximize h(0,0) or (max_match_cost+1)/l
   - Minimize number of extra seeds.
** TODO choosing seeds bases on guessed alignment
** TODO Fix the gap heuristic transpose to take the seeds into account.
** TODO Strategies for choosing seeds:
   - A: Each seed does not match, and covers exactly max_dist+1 mutations.
     - This way, no pruning is needed because there are no matches on the
     diagonal, and h(0,0) exactly equals the actual distance, so that only a
     very narrow region is expanded.
   - B: Maximize the number of seeds that matches exactly (at most 10 times).
   - Experiment: make one mutation every l positions, and make seeds of length l.

*  Pruning
** TODO In-place bruteforce pruning for IncreasingFunction datastructure
** TODO Partial pruning: only prune matches where it is cheap to do so
** TODO Proof that pruning doesn't interact badly with consistency
** TODO Implementation for fast partial pruning:
   - If the current match has no prev/next on the pareto front, *all* previous points must have optimal paths through this match.
   - Removing this match decreases h for *all* previous matches
   - Either bruteforce decrement the value at previous nodes, or keep some log-time datastructure for this.
   - Most of the time, the match will be at the very front and there are going
     to be very few expanded states in front, so we can do an offset and only
     update h for those expanded states beyond this match.
** TODO Pruning with offset
   - Need to figure out when all previous vertices depend on the current match
** TODO Remove matches from indels at the start and ends of seeds. Replace by doing a wider lookup along the diagonal.

*  Performance
** TODO Use Pos(u32,u32) instead of Pos(usize,usize)
** TODO Use array + sorting + binary search to find optimal path.
** DONE Do Greedy extending of edges along diagonals
Whenever a state $(i,j)$ has a matching outgoing edge, we only generate
$(i,j) \to (i+1, j+1)$ and skip the indel edges.
** TODO Skip insertions at the start/end of seeds.
** TODO Prune only half (some fixed %) of matches. This should result in O(matches) total pruning time.
** TODO Prune only matches at (or close to) the 'front': with so far maximal i and j, for not having to update the priority queue.
** TODO Do not generate dist-1 matches with insertions at the start and/or end.
** TODO Do not generate dist-1 matches with deletions at the end.
   - Can deletions at the start also be pruned? It may screw up heuristic values right next to it. Does that matter?
   - Definitely cannot skip deletions at both start and end.
** TODO Replace IncreasingFunction by a vector: value -> position, instead of the current position->value map.
   This is sufficient, because values only increase by 1 or 2 at a time anyway, and set lookup becomes binary search.
** TODO ContourGraph: Add child pointer to incremental state, for faster moving diagonally.
** TODO Investigate gap between h(0,0) and the actual distance.
   - For exact matches, do we want exactly 1 mutation per seed? That way h(0,0) is as large as possible, and we don't have any matches.
** TODO When building ContourGraphs, to get the value at the end of a match,
   instead of walking there using incremental steps, compute and store the value
   of the match once then end-column is processed, but insert it only when the
   start-column is being processed.
** TODO Use SuffixArray instead of multiple QGramIndices for fixed l.
** TODO Update ContourGraph to set the value of a match after processing the end-column, instead of doing a lookup when processing the start column.

* TODO Fast Seed+Gap heuristic implementation:
** Bruteforce from bottom right to top left, fully processing everything all
   matches that are 'shadowed', i.e. only matter for going left/up, but not diagonally anymore.

* Optimizations done:
** Seed Heuristic
** Count Heuristic
** Inexact matches
** Pruning
** sort nodes closer to target first, among those with equal distance+h estimate
   - this almost halves the part of the bandwidth above 1.
** Pruning correctness: Do not prune matches that are next to a better match.
** A* optimizations: together 4x speedup
   - HashMap -> FxHashMap: a faster hash function for ints
   - HashMap -> DiagonalMap: for expanded/explored states, since these are dense on the diagonal.
   - BinaryHeap -> BucketHeap: much much faster; turns log(n) pop into O(1) push&pop
     - For unknown reasons, sorting positions before popping them makes more expanded states, but faster code.
** delete consistency code
** delete incoming edges code
** more efficient edges iteration
** Pre-allocate DiagonalMap edges
** Do internal iteration over outgoing edges, instead of collecting them.
** Sort nodes in IncreasingFunction for better caching
** incremental_h is slowly becoming more efficient (move fewer steps backwards)
** incremental_h: Add Pos==Hint check to incremental_h
