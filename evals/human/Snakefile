# ======= BiWFA test data: 500k+ ONT MinION UL reads ======

rule ont_ul_download:
    output: 'ont-ul/ont_500k.zip'
    shell: 'wget -O {output} https://github.com/smarco/BiWFA-paper/raw/main/evaluation/data/ONT_MinION_UL.500kbps.zip'
rule ont_ul:
    input: 'ont-ul/ont_500k.zip'
    output: 'ont-ul/all.seq'
    params: dir = "ont-ul/"
    shell: '''
    mkdir -p ont-ul/
    unzip {input} -d {params.dir}
    rename seq seq0 {params.dir}/seq?.seq
    cat {params.dir}/*.seq > {output}
    '''

# ===== Block aligner 25kbp ONT test data =====
#
# Note: the download at https://github.com/ocxtal/diffbench/tree/master/seq is the same.
rule block_aligner:
    output: 'block_aligner/sequences.txt'
    shell: '''
    wget -O {output}.gz https://github.com/Daniel-Liu-c0deb0t/diff-bench-paper/releases/download/v1.0/sequences.txt.gz
    gunzip {output}.gz
    '''

# ==== Whole Human Genome Sequencing Project

# Data sources: https://github.com/nanopore-wgs-consortium/NA12878/blob/master/nanopore-human-genome/rel_3_4.md

# Download reference genome.
# Gets the entire directory, but not subdirectories.
REFERENCE_FTP = 'ftp://ftp-trace.ncbi.nih.gov/1000genomes/ftp/technical/reference/GRCh38_reference_genome/'
REFERENCE_DIR = 'nanopore-wgs/reference'
REFERENCE_NAME = f'{REFERENCE_DIR}/GRCh38_full_analysis_set_plus_decoy_hla.fa'
rule download_reference:
    output: REFERENCE_NAME
    shell: f'echo wget -r -nH -nc -l 1 -P {REFERENCE_DIR} --cut-dirs=5 {REFERENCE_FTP}'

# Raw reads
FLOWCELLS = {
    'FAB45271': 'nanopore-human-wgs/rel3-nanopore-wgs-152889212-FAB45271.fastq.gz',
    'FAB42316': 'nanopore-human-wgs/rel3-nanopore-wgs-216722908-FAB42316.fastq.gz',
    'FAB49164': 'nanopore-human-wgs/rel3-nanopore-wgs-4045668814-FAB49164.fastq.gz',
}

# Copy from AWS S3.
# Using AWS CLI is faster, but needs an AWS account and aws CLI set up and linked to your account.
rule download_read_fasta:
    output: 'nanopore-wgs/{id}.fastq.gz'
    run:
        path = FLOWCELLS[wildcards.id]
        #shell('wget -O {output} http://s3.amazonaws.com/{path}')
        shell('aws configure set default.s3.max_concurrent_requests 20')
        shell('aws s3 cp s3://{path} {output}')

rule download_read_bam:
    output: 'nanopore-wgs/{id}.fastq.gz.sorted.bam'
    run:
        path = FLOWCELLS[wildcards.id] + '.sorted.bam'
        for ext in ['', '.bai']:
            #shell('wget -O {output}{ext} http://s3.amazonaws.com/{path}{ext}')
            shell('aws configure set default.s3.max_concurrent_requests 20')
            shell('aws s3 cp s3://{path}{ext} {output}{ext}')

rule download_reads:
    input: [f'nanopore-wgs/{id}.fastq.gz{ext}' for ext in ['', '.sorted.bam'] for id in FLOWCELLS]

# Make .bed file containing reference locations of reads in .bam file:
rule bed_file:
    input: 'nanopore-wgs/{id}.fastq.gz.sorted.bam'
    output: 'nanopore-wgs/{id}.bed'
    shell: 'bedtools bamtobed -i nanopore-wgs/{wildcards.id}.fastq.gz.sorted.bam > {output}'

# Extract parts of reference corresponding to reads:
rule extract_reference:
    input: ['nanopore-wgs/{id}.bed', REFERENCE_NAME]
    output: 'nanopore-wgs/{id}.mapped.fa'
    # -s: reverse-complement the reference when needed
    shell: 'bedtools getfasta -s -nameOnly -fi {REFERENCE_NAME}  -bed nanopore-wgs/{wildcards.id}.bed > {output}'

rule extract_references:
    input: [f'nanopore-wgs/{id}.mapped.fa' for id in FLOWCELLS]

# Reads are in the original .fasta.gz file, or can be extracted using
# samtools fasta {id}.fastq.gz.sorted.bam
# View the bam entry for a read with
# samtools view {read_id}
